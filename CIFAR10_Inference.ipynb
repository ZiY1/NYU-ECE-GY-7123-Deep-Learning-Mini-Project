{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Use the previously saved ckpt.pth file in training to load the Modified ResNet for inference on both the CIFAR10 official test set and the customized test set in Kaggle competition. Has to use GPU to load the ckpt.pth file if previously trained the model with GPU.\n",
        "\n",
        "A sample ckpt.pth file is provided in the ```./checkpoint``` folder."
      ],
      "metadata": {
        "id": "sYQIA_uHxPg4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nuYx7knZv1YY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import sys\n",
        "from google.colab import files\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model\n",
        "First define model as in training session: Blocks->Net->model.\n",
        "\n",
        "Setups has to be exactly the same as the in the training book ```ModifiedResNet_CIFAR.ipynb```.\n",
        "\n",
        "Here the modified shortcut is turned on to match the sample model provided.\n",
        "\n",
        "To turn it off, comment the following lines where ```self.shortcut``` is defined in both the BasicBlock and the PreActBlock,\n",
        "```\n",
        "                nn.MaxPool2d(3, stride = stride, padding = 1),\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=1, bias=False),\n",
        "```\n",
        "and uncomment out the following lines.\n",
        "```\n",
        "                # nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "```\n"
      ],
      "metadata": {
        "id": "U0b6if3zwBMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        # First Convolutional Layer:\n",
        "        # Kernel(Filter) Size: 3 x 3\n",
        "        # Stride: 1\n",
        "        # Padding: 1 (keep the output size equal to the input size if stride is 1)\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        # Batch Normalization\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        # Second Convolutional Layer:\n",
        "        # Kernel Size: 3 x 3\n",
        "        # Stride: 1\n",
        "        # Padding: 1 (keep the output size equal to the input size if stride is 1)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        # Batch Normalization\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        # When the input and output dimensions do not match up,\n",
        "        # use 1x1 convolutional layer to adjust the number of channels\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.MaxPool2d(3, stride = stride, padding = 1),\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=1, bias=False),\n",
        "                # nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                #           kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        # print(\"shape after first weight layer:\", out.shape)\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        # print(\"shape after second weight layer:\", out.shape)\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "FHsdvYVrzFF4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PreActBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    # Full Pre-activation:\n",
        "    # BatchNorm -> Relu -> Conv -> BatchNorm -> Relu -> Conv\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(PreActBlock, self).__init__()\n",
        "\n",
        "        # First Batch Normalization\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        # First Convolutional Layer:\n",
        "        # Kernel(Filter) Size: 3 x 3\n",
        "        # Stride: 1\n",
        "        # Padding: 1 (keep the output size equal to the input size if stride is 1)\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "        # Second Batch Normalization\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        # Second Convolutional Layer:\n",
        "        # Kernel Size: 3 x 3\n",
        "        # Stride: 1\n",
        "        # Padding: 1 (keep the output size equal to the input size if stride is 1)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "\n",
        "\n",
        "        # When the input and output dimensions do not match up,\n",
        "        # use 1x1 convolutional layer to adjust the number of channels\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.MaxPool2d(3, stride = stride, padding = 1),\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=1, bias=False),\n",
        "                # nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                #           kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        # bn-> relu -> conv\n",
        "        out = F.relu(self.bn1(x))\n",
        "        out = self.conv1(out)\n",
        "        # print(\"shape after first weight layer:\", out.shape)\n",
        "        out = F.relu(self.bn2(out))\n",
        "        out = self.conv2(out)\n",
        "        # print(\"shape after second weight layer:\", out.shape)\n",
        "        out += self.shortcut(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "8TqOzmqEMgF5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the Input Layer Convolution is turned off to match the sample model provided.\n",
        "\n",
        "To turn the Convolution back on, change ```kernel_size``` from 1 to 3 and ```padding``` from 0 to 1 when defining ```self.conv1```, and do it backwards to turn if off."
      ],
      "metadata": {
        "id": "Mj4W0gVhFXN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 32\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=1,\n",
        "                               stride=1, padding=0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "fYinV9odzQpU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To match the provided sample, ```PreActBlock``` is used below and the model structure is of (32, [8,6,4,3])"
      ],
      "metadata": {
        "id": "Le7PxR-eGbs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ModifiedResNet():\n",
        "    return ResNet(PreActBlock, [8, 6, 4, 3])"
      ],
      "metadata": {
        "id": "YH7aiIo6zLtA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print('==> Building model..')\n",
        "\n",
        "net = ModifiedResNet()\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HlZOozez3iq",
        "outputId": "5409bbc7-b24c-4f2f-b184-bdfc0fcc8967"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Building model..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Prepare Datasets\n",
        "Then upload the saved ckpt.pth to checkpoint folder."
      ],
      "metadata": {
        "id": "XwxxclQHzpQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isdir('checkpoint'):\n",
        "  os.mkdir('./checkpoint')\n",
        "# upload the ckpt.pth file for the model you would like to use\n",
        "uploaded = files.upload()\n",
        "os.rename('ckpt.pth','./checkpoint/ckpt.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "qwPRWTiTWPMy",
        "outputId": "8f79d3dd-f218-4f17-fd71-05570eb377ea"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-72b1014b-e6e2-4bab-b577-82ba57eebe69\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-72b1014b-e6e2-4bab-b577-82ba57eebe69\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ckpt.pth to ckpt.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if device == 'cuda':\n",
        "  checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
        "net.load_state_dict(checkpoint['net'])\n",
        "best_acc = checkpoint['acc']\n",
        "start_epoch = checkpoint['epoch']"
      ],
      "metadata": {
        "id": "pflz-_PbxOuW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data from the provided file: one from the official test set (test_batch), the other from the customized test set (cifar_test_nolabels.pkl) provided by course staff. Make them tensor datasets and dataloaders. Both of them downloaded and stored in Google Drive."
      ],
      "metadata": {
        "id": "nzdV1KazjbYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1QvbvlZwjW8G-4qDeyFJ6LHu55FJw8UGt #test_batch\n",
        "!gdown 1HhmSG8MmoSHYggm_5Euo6JT1w8Gq-boW #cifar_test_nolabels.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJxoZMu2bP2z",
        "outputId": "4025cd85-7edf-4104-afb6-b8e9cfe32de8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QvbvlZwjW8G-4qDeyFJ6LHu55FJw8UGt\n",
            "To: /content/test_batch\n",
            "100% 31.0M/31.0M [00:00<00:00, 76.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HhmSG8MmoSHYggm_5Euo6JT1w8Gq-boW\n",
            "To: /content/cifar_test_nolabels.pkl\n",
            "100% 30.8M/30.8M [00:00<00:00, 95.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "def cifar10_plot(data, im_idx=0):\n",
        "    im = data[b'data'][im_idx, :]\n",
        "\n",
        "    im_r = im[0:1024].reshape(32, 32)\n",
        "    im_g = im[1024:2048].reshape(32, 32)\n",
        "    im_b = im[2048:].reshape(32, 32)\n",
        "\n",
        "    img = np.dstack((im_r, im_g, im_b))\n",
        "\n",
        "    print(\"shape: \", img.shape)\n",
        "    # print(\"label: \", data[b'labels'][im_idx])\n",
        "    # print(\"category:\", meta[b'label_names'][data[b'labels'][im_idx]])\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "yGpaeD7ABJDC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, target, transform=None, target_transform=None):\n",
        "        self.data = data\n",
        "        self.target = target\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        y = self.target[index]\n",
        "        if self.target_transform:\n",
        "            y = self.target_transform(y)\n",
        "\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "MrAFNOo6yZV5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset and dataloader marked with 'nolabel' is for the customized dataset, 'official' is for the actual CIFAR test dataset."
      ],
      "metadata": {
        "id": "T2xE_H4t3-36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_nolabel = unpickle(\"cifar_test_nolabels.pkl\")\n",
        "test_data_nolabel = np.transpose(np.reshape(test_nolabel[b'data'],(-1, 3, 32, 32)),(0,2,3,1))\n",
        "test_dataID_nolabel = test_nolabel[b'ids']\n",
        "\n",
        "test_official = unpickle(\"test_batch\")\n",
        "test_data_official = np.transpose(np.reshape(test_official[b'data'],(-1, 3, 32, 32)),(0,2,3,1))\n",
        "test_label_official = test_official[b'labels']\n"
      ],
      "metadata": {
        "id": "weTtzZ9ydbbY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a look at the image loded"
      ],
      "metadata": {
        "id": "q632yPWFIG9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10_plot(test_nolabel,1001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ajEodf2HDqhq",
        "outputId": "97f01896-152b-4701-8bcb-8af6ccc4b075"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape:  (32, 32, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the same standarization on the test set as the training set\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "test_nolabel_dataset = MyDataset(test_data_nolabel, test_dataID_nolabel, transform = transform_test)\n",
        "test_official_dataset = MyDataset(test_data_official, test_label_official, transform = transform_test)\n",
        "\n",
        "testloader_oset = torch.utils.data.DataLoader(\n",
        "    test_official_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "testloader_nset = torch.utils.data.DataLoader(\n",
        "    test_nolabel_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "X8QJTf5NlQKz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = next(iter(testloader_oset))\n",
        "print(image.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nygNpZXDw_dY",
        "outputId": "4fb5a62c-dc11-4667-a51e-d51860cfd11f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Inference\n",
        "First inference on the official test set to see if it matches the result from the training book"
      ],
      "metadata": {
        "id": "LAJ2_LUVj9WV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def test(testloader):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(batch_idx, len(testloader), 'Loss: %.3f | Test Acc: %.3f%% (%d/%d)'\n",
        "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "        print(\"Total accuracy for official test set: %.3f %%\"%(100.*correct/total))\n"
      ],
      "metadata": {
        "id": "0XwmYK1EkBfC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(testloader_oset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T3qGMv9k6Cv",
        "outputId": "ff8a6a5b-6614-4645-de17-594f2d1bdebb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 100 Loss: 0.137 | Test Acc: 97.000% (97/100)\n",
            "10 100 Loss: 0.204 | Test Acc: 95.364% (1049/1100)\n",
            "20 100 Loss: 0.231 | Test Acc: 94.619% (1987/2100)\n",
            "30 100 Loss: 0.238 | Test Acc: 94.839% (2940/3100)\n",
            "40 100 Loss: 0.233 | Test Acc: 94.927% (3892/4100)\n",
            "50 100 Loss: 0.234 | Test Acc: 94.980% (4844/5100)\n",
            "60 100 Loss: 0.225 | Test Acc: 95.131% (5803/6100)\n",
            "70 100 Loss: 0.215 | Test Acc: 95.197% (6759/7100)\n",
            "80 100 Loss: 0.217 | Test Acc: 95.123% (7705/8100)\n",
            "90 100 Loss: 0.212 | Test Acc: 95.242% (8667/9100)\n",
            "Total accuracy for official test set: 95.250 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All look good. Now apply on the no label dataset and make the Submission.csv file - note here the \"target\" is replaced by the data ID since there's no label for the data set."
      ],
      "metadata": {
        "id": "2OB0OlZn4nKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_submission(testloader):\n",
        "    result = np.zeros((10000,2))\n",
        "    net.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "          result[batch_idx*100:(batch_idx+1)*100, 0] = targets\n",
        "          inputs, targets = inputs.to(device), targets.to(device)\n",
        "          outputs = net(inputs)\n",
        "\n",
        "          _, predicted = outputs.max(1)\n",
        "          predicted = np.array(predicted.cpu())\n",
        "          result[batch_idx*100:(batch_idx+1)*100, 1] = predicted\n",
        "    result = result.astype(int)\n",
        "    return result"
      ],
      "metadata": {
        "id": "Ll_3cInx4uL2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_official = create_submission(testloader_oset)\n",
        "result_nolabel = create_submission(testloader_nset)\n",
        "np.savetxt('submission.csv',result_nolabel,delimiter=',',fmt='%d',header='ID,Labels')"
      ],
      "metadata": {
        "id": "djJd7LdoJ1Pl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result_nolabel[1000:1020,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWYQ3Z0N_sZH",
        "outputId": "3cab5941-3abd-4371-a70a-6f389b1650a7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1000    4]\n",
            " [1001    2]\n",
            " [1002    2]\n",
            " [1003    2]\n",
            " [1004    3]\n",
            " [1005    2]\n",
            " [1006    2]\n",
            " [1007    2]\n",
            " [1008    2]\n",
            " [1009    2]\n",
            " [1010    2]\n",
            " [1011    2]\n",
            " [1012    3]\n",
            " [1013    2]\n",
            " [1014    2]\n",
            " [1015    2]\n",
            " [1016    2]\n",
            " [1017    2]\n",
            " [1018    2]\n",
            " [1019    2]]\n"
          ]
        }
      ]
    }
  ]
}